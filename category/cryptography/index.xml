<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cryptography | Luminolt</title><link>https://example.com/category/cryptography/</link><atom:link href="https://example.com/category/cryptography/index.xml" rel="self" type="application/rss+xml"/><description>Cryptography</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 17 Jul 2022 16:34:34 +0800</lastBuildDate><image><url>https://example.com/media/icon_hu1b90dea3b5752ec4ed6154c0dc881a21_30314_512x512_fill_lanczos_center_3.png</url><title>Cryptography</title><link>https://example.com/category/cryptography/</link></image><item><title>Note - HE-Based PPML</title><link>https://example.com/post/note-ppml/</link><pubDate>Sun, 17 Jul 2022 16:34:34 +0800</pubDate><guid>https://example.com/post/note-ppml/</guid><description>&lt;p>本文为基于同态性质的PPML方案的综述，以下为主要参考文献的信息：&lt;/p>
&lt;blockquote>
&lt;p>Article: Efficient Dropout-resilient Aggregation for Privacy-preserving Machine Learning&lt;/p>
&lt;p>Journal: TIFS (IEEE Transactions on Information Forensics and Security)&lt;/p>
&lt;p>Author: Ziyao Liu, Jiale Guo, Kwok-Yan Lam, Jun Zhao&lt;/p>
&lt;p>Date: AUGUST 2021&lt;/p>
&lt;/blockquote>
&lt;h1 id="1-background">1. Background&lt;/h1>
&lt;p>机器学习是目前信息技术的一个主要方向，其要求数据量巨大的特性造成了对于用户共享数据集的需求。而为了保护用户的数据隐私，隐私保护机器学习（Privacy-preserving Machine Learning, PPML）近年来受到关注。&lt;/p>
&lt;p>在大规模机器学习中，用户或设备随时会退出（dropout），本文对此提出了一种可扩展的隐私聚合方案，通过同态伪随机数生成器（Homomorphic Pseudorandom Generator, HPRG）、Shamir秘密共享和数字签名方案，构建了一种PPML方案。该方案的特点包括：&lt;/p>
&lt;ul>
&lt;li>动态性：用户或设备可以随时退出；&lt;/li>
&lt;li>安全性：可抵抗半诚实用户和恶意敌手的攻击；&lt;/li>
&lt;li>高效性：相较于传统方案（SecAgg）更快。&lt;/li>
&lt;/ul>
&lt;h3 id="compare">Compare&lt;/h3>
&lt;p>以下为以往工作的一些特点：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Article Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Privacy-preserving stream aggregation with fault tolerance&lt;/td>
&lt;td>阈值HE，高开销的building block，对大规模PPML不现实&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Privacy-preserving deep learning via additively homomorphic encryption&lt;/td>
&lt;td>比上述高效，但存在梯度泄露&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Mpc-enabled privacypreserving neural network training against malicious attack&lt;/td>
&lt;td>依靠MPC，DNN的通信开销很大&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Aby3: A mixed protocol framework for machine learning&lt;/td>
&lt;td>服务器辅助MPC，但对于单个服务器不能保证非共谋性&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Falcon: Honest-majority maliciously secure framework for private deep learning&lt;/td>
&lt;td>同上&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Practical secure aggregation for privacy-preserving machine learning&lt;/td>
&lt;td>pair-wise DH，抗退出（弹性）&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;div class="alert alert-note">
&lt;div>
&lt;p>名词缩写&lt;/p>
&lt;p>HE：同态加密；MPC：多方安全计算；DNN：深度神经网络；DH：Diffie-Hellman&lt;/p>
&lt;/div>
&lt;/div>
&lt;h1 id="2-protocol">2. Protocol&lt;/h1>
&lt;p>此处会提及两篇文章的内容，为方便下做简称：&lt;/p>
&lt;ul>
&lt;li>EDRAgg：即本文的主要参考文献，Efficient Dropout-resilient Aggregation for Privacy-preserving Machine Learning&lt;/li>
&lt;li>SecAgg：来自Google的最早的方案，Practical secure aggregation for privacy-preserving machine learning&lt;/li>
&lt;/ul>
&lt;h2 id="21-masking-model">2.1 Masking Model&lt;/h2>
&lt;p>首先需要明确我们的目标。在目前的研究中，PPML的底层是由安全聚合协议支持的。在该环境下，我们进行如下的定义：&lt;/p>
&lt;p>设存在用户集 $\mathcal{U}$ 和服务器集 $\mathcal{S}$，用户$u_i\in \mathcal{U}$拥有的ML模型参数记作$\boldsymbol{x_i}$，则安全聚合的目标是在不泄露 $\boldsymbol{x_i}$ 的任何信息的情况下，使得服务器获得聚合参数 $\boldsymbol{y} = \sum_{u_i \in \mathcal{U}} \boldsymbol{x_i}$ 。&lt;/p>
&lt;div class="alert alert-note">
&lt;div>
&lt;p>🤔此处“不泄露”针对的是 $o_j \in \mathcal{U} \cup \mathcal{S} \backslash \{u_i\}$&lt;/p>
&lt;p>类似完美安全性，$o_j$在协议前后的视角不变（同分布）&lt;/p>
&lt;/div>
&lt;/div>
&lt;h3 id="an-example">An Example&lt;/h3>
&lt;p>此处我们考虑两个用户，一个服务器的情况，即 $\mathcal{U} = \{u_1,u_2\}$，$\mathcal{S} = \{s\}$。&lt;/p>
&lt;p>此时，想要不泄露任何信息，可让用户对自己的模型参数加上遮罩（mask），再使服务器能够消除遮罩即可。我们将遮罩记作$\boldsymbol{r_i}$，则有：&lt;/p>
&lt;p>$$
\boldsymbol{y_i} = \boldsymbol{x_i} + \boldsymbol{r_i}
$$&lt;/p>
&lt;p>于是对于两个用户的情况如下图所示，此处$r_i$为随机选取的随机数：&lt;/p>
&lt;img src="https://picgo-1303220879.cos.ap-shanghai.myqcloud.com/img/20220728080035.png" style="zoom: 33%;" />
&lt;p>此时，只需要服务器能过获得$\sum \boldsymbol{r} =\boldsymbol{r_1} + \boldsymbol{r_2}$，就可以消除遮罩，但显然这又变成了一个安全聚合问题。此时一个巧妙的方法是让$\sum \boldsymbol{r} =0$，即$\boldsymbol{r_1} =- \boldsymbol{r_2}$，对于该情况，可以让$u_1$向$u_2$发送$\boldsymbol{r_1}$，如图：&lt;/p>
&lt;img src="https://picgo-1303220879.cos.ap-shanghai.myqcloud.com/img/image-20220728081126187.png" alt="image-20220728081126187" style="zoom: 50%;" />
&lt;p>此时，$\boldsymbol{y_1}+\boldsymbol{y_2}$恰为$\boldsymbol{x_1}+\boldsymbol{x_2}$，且服务器从$\boldsymbol{y_1},\boldsymbol{y_2}$不能获得与$\boldsymbol{x_1},\boldsymbol{x_2}$相关的任何信息。&lt;/p>
&lt;div class="alert alert-note">
&lt;div>
需注意的是，此处要求$len(\boldsymbol{r_i})\geq len(\boldsymbol{x_i})$，即满足One-time Pad，具有完美安全性。
&lt;/div>
&lt;/div>
&lt;p>但随之而来，会发现有一个问题，由于$u_2$从$u_1$处获得了$\boldsymbol{r_1}$，如果$u_2$和服务器$s$共谋，则可以还原$\boldsymbol{x_1}=\boldsymbol{y_1}-\boldsymbol{r_1}$，从而导致$u_1$的ML模型参数泄露。有什么方法可以让$u_1,u_2$双方共享一个数，并且不能被别人获取呢？此处就需要引入SecAgg的工作，巧妙利用Diffie-Hellman密钥交换算法来完成目标。&lt;/p>
&lt;p>此处我们省去关于DH密码学原语的详细说明，观察下图不难发现DH天然的给出了一个双方共享的数$g^{ab}$，且由于计算该数$g^{ab}=(g^a)^b=(g^b)^a$，要求一方的公钥和另一方的私钥，不会把信息泄露给第三方。&lt;/p>
&lt;img src="https://picgo-1303220879.cos.ap-shanghai.myqcloud.com/img/image-20220728082043225.png" alt="image-20220728082043225" style="zoom:33%;" />
&lt;p>这就得到了一个基于DH的安全聚合方法（作者称该过程为 pair-wise DH）。&lt;/p>
&lt;div class="alert alert-note">
&lt;div>
由于显然存在可逆映射$F:\mathbb{Z}_p^k\rightarrow \mathbb{Z}_p$将参数向量降维，此处将$\boldsymbol{r_i}$ 规约到 $\mathbb{Z}_p$上，下同理。
&lt;/div>
&lt;/div>
&lt;h3 id="further-example-more-users">Further Example, More Users&lt;/h3>
&lt;p>我们进一步扩展用户集的数量至3人，该方法是否还可行呢？&lt;/p>
&lt;img src="https://picgo-1303220879.cos.ap-shanghai.myqcloud.com/img/image-20220728082623247.png" alt="image-20220728082623247" style="zoom:33%;" />
&lt;p>我们可以从$u_1$的视角考虑：&lt;/p>
&lt;img src="https://picgo-1303220879.cos.ap-shanghai.myqcloud.com/img/image-20220728082755491.png" alt="image-20220728082755491" style="zoom:33%;" />
&lt;p>用户$u_1$除了自己的私钥$a$外，还可以得知$u_1,u_2,u_3$的公钥$g^a,g^b,g^c$，于是相关可计算$g^{ab},g^{ac}$。我们不妨使$u_1$的mask恰为$r_1=g^{ab}+g^{ac}$，那么与之对应在计算$u_2$的mask时，由于需要和$g^{ab}$配对相消，使之为$r_2=-g^{ab}+g^{bc}$，$u_3$同理，如图所示。&lt;/p>
&lt;img src="https://picgo-1303220879.cos.ap-shanghai.myqcloud.com/img/image-20220728083114276.png" alt="image-20220728083114276" style="zoom:50%;" />
&lt;p>不难归纳出该方法的计算公式：
$$
y_i=x_i+\sum_{i&amp;lt;j}g^{sk_isk_j}-\sum_{i&amp;gt;j}g^{sk_isk_j}
$$
则显然：
$$
y=\sum_{u_i\in\mathcal{U}}{y_i}=\sum_{u_i\in\mathcal{U}}{\left(x_i+\sum_{i&amp;lt;j}g^{sk_isk_j}-\sum_{i&amp;gt;j}g^{sk_isk_j}\right)}=\sum_{u_i\in\mathcal{U}}{x}
$$&lt;/p>
&lt;h3 id="another-method">Another Method&lt;/h3>
&lt;p>（待更新……）&lt;/p>
&lt;h2 id="22-security-analysis">2.2 Security Analysis&lt;/h2>
&lt;p>（待更新……）&lt;/p>
&lt;h1 id="3-summary">3. Summary&lt;/h1>
&lt;p>（待更新……）&lt;/p>
&lt;!-- $\boldsymbol{R}=\sum r_i=\mathcal{F}(\boldsymbol{R}^1,\boldsymbol{R}^2,\cdots,\boldsymbol{R}^n)$ --></description></item></channel></rss>